# ğŸšš T3 Food Trucks Data Pipeline

A data lake solution for Tasty Truck Treats (T3), migrating transaction data from RDS to AWS S3 with Athena querying and Streamlit dashboards.

## Overview

T3 operates a fleet of food trucks in Lichfield and surrounding areas, each offering unique menus and culinary experiences. The trucks operate semi-independently, uploading sales data to a central database every few hours.

### The Problem

The company's existing RDS MySQL infrastructure has become increasingly expensive to maintain. As T3 explores potential acquisition opportunities, demonstrating a robust and cost-effective data architecture is critical for financial stability.

### The Solution

This project implements a complete data migration from RDS to a modern data lake architecture:

- **Cost Reduction**: S3 storage is significantly cheaper than RDS for historical data
- **Scalability**: Parquet format with time-based partitioning enables efficient querying at scale
- **Flexibility**: Athena provides serverless, pay-per-query analytics without managing infrastructure
- **Accessibility**: Streamlit dashboards give stakeholders real-time insights into fleet performance

### Key Features

- ğŸ”„ Automated ETL pipeline for historical and periodic data migration
- ğŸ“Š Interactive dashboard for revenue, truck performance, and sales patterns
- ğŸ“§ Daily automated reports delivered via Lambda
- ğŸ—ï¸ Infrastructure as Code with Terraform for reproducible deployments
- ğŸ³ Dockerized components for consistent environments

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RDS       â”‚â”€â”€â”€â”€â–¶â”‚   Extract   â”‚â”€â”€â”€â”€â–¶â”‚  Transform  â”‚â”€â”€â”€â”€â–¶â”‚   S3 Data   â”‚
â”‚   MySQL     â”‚     â”‚   (Python)  â”‚     â”‚  (Parquet)  â”‚     â”‚    Lake     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                   â”‚
                                                                   â–¼
                                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚  Streamlit  â”‚â—€â”€â”€â”€â”€â”‚   Athena    â”‚
                                        â”‚  Dashboard  â”‚     â”‚   Queries   â”‚
                                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
T3-Food-Trucks/
â”œâ”€â”€ pipeline/                    # ETL pipeline
â”‚   â”œâ”€â”€ extract.py              # Extract data from RDS
â”‚   â”œâ”€â”€ transform.py            # Clean and transform data
â”‚   â”œâ”€â”€ create_parquet.py       # Convert to Parquet format
â”‚   â”œâ”€â”€ upload_to_s3.py         # Upload to S3 data lake
â”‚   â”œâ”€â”€ pipeline.py             # Main orchestration script
â”‚   â”œâ”€â”€ exploration.ipynb       # Data exploration notebook
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ dashboard/                   # Streamlit dashboard
â”‚   â”œâ”€â”€ dashboard.py            # Main dashboard app
â”‚   â”œâ”€â”€ queries.py              # Athena query functions
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ daily report/               # Lambda report generator
â”‚   â”œâ”€â”€ generate_report.py      # Daily HTML report
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ terraform/                  # Infrastructure as Code
â”‚   â”œâ”€â”€ main.tf
â”‚   â””â”€â”€ variables.tf
â””â”€â”€ case_study.md
```

## Tech Stack

| Component | Technology |
|-----------|------------|
| Storage | AWS S3 |
| Query Engine | AWS Athena |
| Database (Source) | AWS RDS MySQL |
| ETL | Python, Pandas |
| Data Format | Parquet (partitioned by date) |
| Dashboard | Streamlit, Plotly |
| Infrastructure | Terraform |
| Containerization | Docker |

## Data Schema

The source data uses a STAR schema:

- **DIM_Truck** - Truck information (name, FSA rating, card reader status)
- **DIM_Payment_Method** - Payment method types
- **FACT_Transaction** - Sales transactions (timestamp, amount, truck, payment method)

## Setup

### Prerequisites

- Python 3.12+
- Docker
- AWS CLI configured
- Terraform

### Environment Variables

Create a `.env` file in the project root:

```env
DB_HOST=your-rds-endpoint
DB_PORT=3306
DB_USER=your-username
DB_PASSWORD=your-password
DB_NAME=your-database

S3_BUCKET_NAME=your-s3-bucket
ATHENA_DATABASE=your-athena-database
```

### Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/your-repo/T3-Food-Trucks.git
   cd T3-Food-Trucks
   ```

2. Install dependencies for each component:
   ```bash
   pip install -r pipeline/pipeline_requirements.txt
   pip install -r dashboard/dashboard_requirements.txt
   ```

## Usage

### Run the ETL Pipeline

```bash
cd pipeline
python pipeline.py
```

Or with Docker:
```bash
docker build -t t3-pipeline ./pipeline
docker run --env-file .env t3-pipeline
```

### Run the Dashboard

```bash
cd dashboard
streamlit run dashboard.py
```

Or with Docker:
```bash
docker build -t t3-dashboard ./dashboard
docker run -p 8501:8501 --env-file .env t3-dashboard
```

Access at: http://localhost:8501

### Deploy Infrastructure

```bash
cd terraform
terraform init
terraform plan
terraform apply
```

## Pipeline Steps

1. **Extract** - Pull data from RDS MySQL into CSV files
2. **Transform** - Clean, deduplicate, and validate data
3. **Create Parquet** - Convert to time-partitioned Parquet files
4. **Upload** - Push to S3 data lake

## Dashboard Features

- ğŸ“Š Daily revenue trends
- ğŸšš Truck performance comparison
- ğŸ’³ Payment method distribution
- â° Hourly sales patterns
- ğŸ“… Day of week analysis

## Stakeholders

| Name | Role | Priority |
|------|------|----------|
| Hiram Boulie | CFO | Cost reduction, profitability |
| Miranda Courcelle | Head of Culinary Experience | Menu optimization, location insights |
| Alexander D'Torre | Head of Technology | Scalable, cost-effective architecture |

## License

Internal project for Tasty Truck Treats (T3).